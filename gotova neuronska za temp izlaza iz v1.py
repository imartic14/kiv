# -*- coding: utf-8 -*-
"""kiv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14sJTx8IrAzgbFMEtaUxBhYC2m6ObPWJD
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from torch import nn

import pandas as pd

EPOCHS = 15000
LR = 0.0005
BATCH_SIZE = 200

x = pd.read_excel('/content/sample_data/xtrain.xlsx')
y = pd.read_excel('/content/sample_data/ytrain.xlsx')

x = x.to_numpy()
y = y.to_numpy()

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

print(x_train.shape)
print(x_test.shape)
print(x_valid.shape)

x_train[0]

import torch.nn.functional as F

class InesNet(nn.Module):

    def __init__(self):
        super(InesNet, self).__init__()
        self.fc1 = nn.Linear(2, 32)  
        self.fc2 = nn.Linear(32, 64)
        self.fc3 = nn.Linear(64, 64)
        self.fc4 = nn.Linear(64, 1)
      
 
    def forward(self, x):
        x1 = F.relu(self.fc1(x))
        x2 = F.relu(self.fc2(x1))
        x3 = F.relu(self.fc3(x2))
        y = self.fc4(x3)
        return y

def normalize(x):
  x_normed = x / x.max(0, keepdim=True)[0]
  return x_normed

net =  InesNet()
net

from torch.utils.data import TensorDataset, DataLoader



x_train_tensor = torch.Tensor(x_train)
y_train_tensor = torch.Tensor(y_train)

x_test_tensor = torch.Tensor(x_test)
y_test_tensor = torch.Tensor(y_test)

x_valid_tensor = torch.Tensor(x_valid)
y_valid_tensor = torch.Tensor(y_valid)

x_train_tensor = normalize(x_train_tensor)
x_test_tensor = normalize(x_test_tensor)
x_valid_tensor = normalize(x_valid_tensor)

test_dataset = TensorDataset(x_test_tensor, y_test_tensor)
test_dataloader = DataLoader(test_dataset)

train_dataset = TensorDataset(x_train_tensor, y_train_tensor)
train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)

valid_dataset = TensorDataset(x_valid_tensor, y_valid_tensor)
valid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=BATCH_SIZE)

import torch.optim as optim

criterion = nn.MSELoss()
optimizer = optim.Adam(net.parameters(), lr=LR)



train_loss = []
valid_loss = []
for epoch in range(EPOCHS):

  net.train()

  running_loss = 0
  epoch_loss_train = 0
  epoch_loss_valid = 0

  
  for inputs, labels in train_dataloader:
    optimizer.zero_grad()

    # forward + backward + optimize
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    epoch_loss_train += outputs.shape[0] * loss.item()

  for inputs, labels in valid_dataloader:

    outputs = net(inputs)
    loss = criterion(outputs, labels)

    epoch_loss_valid += outputs.shape[0] * loss.item()

  if (epoch + 1) % 100 == 0:
    print(epoch + 1, epoch_loss_train / len(train_dataset), epoch_loss_valid / len(valid_dataset))
  train_loss.append(epoch_loss_train / len(train_dataset))
  valid_loss.append(epoch_loss_valid / len(valid_dataset))

plt.plot(train_loss, label="train loss")
plt.plot(valid_loss, label="valid loss")
plt.ylim([0, 100])
plt.grid()
plt.legend()
plt.show()



from matplotlib.pyplot import figure


outputs = []
labels = []
mses = []
net.eval()
for input, label in test_dataloader:
  output = net(input)
  outputs.append(output.item())
  labels.append(label.item())
  mses.append((output.item() - label.item() ** 2))
  # print(labels)
  # print(output)

print(np.mean(mses))
figure(figsize=(32, 10))

plt.plot(outputs, label="pred")
plt.plot(labels, label="label")
plt.legend()
plt.grid()
plt.show()

predict_data = pd.read_excel('/content/sample_data/predict.xlsx')

predict_data = predict_data.to_numpy()


predict_tensor = torch.Tensor(predict_data)

predict_tensor = normalize(predict_tensor)

predict_dataset = TensorDataset(predict_tensor)
predict_dataloader = DataLoader(predict_dataset)

predicted = []
for input in predict_dataloader:
  output = net(input[0])
  predicted.append(output.item())
  print(output.item())


plt.plot(predicted)
plt.show()

from sklearn import preprocessing
 
scaler = preprocessing.StandardScaler().fit(x)
x_norm = scaler.transform(x)
 
x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.2)
 
from sklearn import linear_model
from sklearn.metrics import mean_squared_error
 
for i in [-10, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:
    reg = linear_model.Ridge(alpha=i)
 
    reg.fit(x_train, y_train)
    pred = reg.predict(x_test)
 
    print(i, mean_squared_error(y_test, pred))